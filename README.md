MercadoPago ML Pipeline

Goal: build a machine learningâ€“ready dataset for ordering Value Propositions (Value Props) shown in MercadoPagoâ€™s â€œDescubrÃ­ MÃ¡sâ€ carousel.

The pipeline ingests prints, taps, and payments (JSONL/CSV), validates them with Pydantic (row-level) and Pandera (DataFrame-level), applies quality checks, and emits datasets ready for feature engineering (clicked target + 21-day lookbacks).

```bash
mercadopago-ml-pipeline/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ params.yaml             # Central configuration (paths, windows, thresholds)
â”œâ”€â”€ management/
â”‚   â””â”€â”€ logging_config.py       # Logging bootstrap & ProgressTracker
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ carrusel_mp/
â”‚   â”‚   â””â”€â”€ processing/
â”‚   â”‚   â”‚   â””â”€â”€ aggregators.py        # utilities for calculation in aggregation dataset
â”‚   â”‚   â”‚   â””â”€â”€ feature_engine.py     # Feature processing engine
â”‚   â”‚   â”‚   â””â”€â”€ preprocess_engine.py  # health check for data before processing
â”‚   â”‚   â””â”€â”€ config.py           # Config loader, env overrides, validation bounds
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ extractors.py       # DataExtractor base + Prints/Taps/Payments
â”‚   â”‚   â”œâ”€â”€ loaders.py          # JSONL/CSV chunked readers
â”‚   â”‚   â””â”€â”€ validators.py       # Cross-source validators (e.g. taps must have prints)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ contracts.py        # Pandera schemas (raw, processed, final)
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models (Print, Tap, Payment, Results)
â”‚   â””â”€â”€ utils/
â”‚           â”œâ”€â”€ time_utils.py   # UTC/time parsing helpers
â”‚           â””â”€â”€ quality_utils.py # Simple quality summaries & logging
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py         # End-to-end runner (Bronzeâ†’Silverâ†’Gold)
â”‚   â””â”€â”€ performance_analysis.py # (optional) perf tips
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ input/                  # Example raw batch (prints.json, taps.json, pays.csv)
â”‚   â”œâ”€â”€ processed/              # Example â€œSilverâ€ CSVs
â”‚   â””â”€â”€ output/                 # Example â€œGoldâ€ CSV
â”‚
â””â”€â”€ data/                       # Storage (gitignored in prod)
    â”œâ”€â”€ raw/                    # Bronze: raw inputs
    â”œâ”€â”€ processed/              # Silver: cleaned with metadata (+ rejects/manifests)
    â””â”€â”€ output/                 # Gold: ML-ready dataset

```

ğŸ”‘ Core Components
1) Configuration (config/params.yaml + src/carrusel_mp/config.py)

Paths, chunk sizes, memory caps, validation windows, thresholds

YAML â†’ dataclasses + env overrides (e.g. MP_LOG_DIR, MP_VALIDATE_SCHEMA)

Validation bounds for timestamps (e.g., validation.business_rules.min_timestamp_days_ago)

Ensures data directories exist

2) Logging (management/logging_config.py)

logging.config.dictConfig structured logs

Rotating file handler + optional console output

ProgressTracker for stepwise reporting
 
 ``` yaml
ğŸš€ start: extraction
ğŸ“ˆ [2/5] (40.0%) processed taps
âœ… done: extraction (duration: 12.34s)
```

3) Models

Pydantic (src/models/schemas.py)

Validate each row: PrintRecord, TapRecord, PaymentRecord

Enforce ID formats, timestamp bounds (UTC), amount limits

BatchProcessingResult for batch metrics

Pandera (src/models/contracts.py)

Validate entire DataFrames

strict=False for raw (optional position)

strict=True for processed/final

Leverages config bounds and max payment amount

4) Data Extractors (src/data/extractors.py)

Abstract DataExtractor (generic over Pydantic model + Pandera schema)

Chunked readers via src/data/loaders.py

Normalize raw â†’ canonical:

prints/taps: day â†’ timestamp (UTC), event_data.{value_prop, position} â†’ value_prop_id, position

payments: pay_date â†’ timestamp, total â†’ amount

Rejects to data/processed/_rejects/*.csv, manifests to data/processed/_manifests/*.json

5) Preprocessing & Features

Preprocessing (in the runner): UTC coercion, dedupe, metadata, basic type fixes

Features (in the runner):

clicked target (tap exists same (user_id, value_prop_id, date))

21-day trailing lookbacks: prints_count_3w, taps_count_3w, payments_count_3w, payments_amount_3w

6) Validators (src/data/validators.py)

Example: taps_have_prints â€” % of taps that have a print same (user_id, value_prop_id, date)

ğŸ§© Data Flow
ETL Flow (Bronze â†’ Silver â†’ Gold)

``` text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  prints.json  â”‚â”€â”€â”€â–º â”‚ PrintsExtractor  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   taps.json   â”‚â”€â”€â”€â–º â”‚ TapsExtractor    â”‚â”€â”€â”€â–º  Silver: processed/validated
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        (+ rejects, manifests)
â”‚   pays.csv    â”‚â”€â”€â”€â–º â”‚ PaymentsExtractorâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Feature engineering    â”‚â”€â”€â”€â–º  Gold: final training dataset
                  â”‚  (clicked + 21d feats)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

Extraction Workflow

``` text
[Raw file]
   â”‚
   â–¼
[Loader (chunk)]
   â”‚
   â–¼
[Normalize]
   â”‚
   â–¼
[Pydantic row validate]
   â”‚
   â–¼
[Pandera DF validate]
   â”‚
   â–¼
[Processed chunk] â†’ [Yield / Write]


```

âš™ï¸ Usage.
0) Install


``` bash
python -m venv .venv
source .venv/bin/activate           # (On Windows: .venv\Scripts\activate)
python -m pip install --upgrade pip
pip install -r requirements/base.txt

```

1) Place inputs

Either copy your own month of data into data/raw/:

prints.json (JSON Lines)

taps.json (JSON Lines)

pays.csv (CSV)


Run the pipeline:
Ensure the repo root is on PYTHONPATH so src/... imports resolve:
```bash
PYTHONPATH=. python scripts/run_pipeline.py
```

4) Outputs

Silver (Parquet):

data/processed/prints.parquet

data/processed/taps.parquet

data/processed/payments.parquet

plus _rejects/*.csv and _manifests/*.json

Gold (Parquet):

data/output/training_dataset.parquet

Quality Report:

data/quality_reports/quality_report.json

Logs:

logs/pipeline.log

Quality/Validation

Row-level: Pydantic (schemas.py)

Frame-level: Pandera (contracts.py) with strict=False (raw) / strict=True (processed/final)

Business checks:

max payment <= validation.business_rules.max_payment_amount

timestamps within validation.business_rules.min_timestamp_days_ago window

optional: taps_have_prints metric in validators.py

âš™ï¸ Configuration & Logging Flow:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  config/params.yaml   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ YAML load + env overrides
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ src/carrusel_mp/config.py    â”‚
â”‚   - DataPaths                â”‚
â”‚   - ProcessingConfig         â”‚
â”‚   - QualityConfig            â”‚
â”‚   - LoggingCfg               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ provides cfg objects
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ management/logging_config.py â”‚
â”‚   setup_logging()            â”‚
â”‚   ProgressTracker            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ structured logs + rotation
          â–¼
      Application Runtime

```

Orchestration
GitHub Actions (CI runner)

```yaml
name: ml-pipeline
on:
  push:
    branches: [ main ]
  workflow_dispatch: {}

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/base.txt

      - name: Prepare example data
        run: |
          mkdir -p data/raw
          cp -r examples/input/* data/raw/
          ls -la data/raw

      - name: Run pipeline
        env:
          MP_LOG_DIR: logs
          MP_VALIDATE_SCHEMA: "true"
          PYTHONPATH: .
        run: |
          python scripts/run_pipeline.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-artifacts
          path: |
            data/processed/**
            data/output/**
            data/quality_reports/**
            logs/**

```
Airflow DAG (concept)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        extract           â”‚ â”€â”€â”€â–º â”‚       preprocess         â”‚
â”‚  (read + normalize raw)  â”‚      â”‚  (UTC, dedupe, metadata) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        features          â”‚
              â”‚  (clicked + 21d feats)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚         quality          â”‚
              â”‚ (rules + report JSON)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

